import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.express as px
from scipy.stats import ttest_ind, levene
import scipy.stats as stats
import statsmodels.api as sm
from statsmodels.stats.diagnostic import het_breuschpagan
from sklearn.linear_model import LinearRegression
from sklearn.feature_selection import RFE
from statsmodels.stats.outliers_influence import variance_inflation_factor

# Configuraci√≥n inicial
st.set_page_config(page_title="An√°lisis de Felicidad Global", page_icon="üòä", layout="wide")

# Cargar datos
@st.cache_data
def load_data():
    return pd.read_csv('2019.csv')

df = load_data()

# T√≠tulo principal
st.title("An√°lisis del √çndice de Felicidad Mundial üåç")
st.markdown("""
**Integrantes:**
- Javier Alejandro Gonz√°lez D√≠az C-312
- Kevin M√°rquez Vega C-312
- Jos√© Miguel Leyva de la Cruz C-312
""")

# Sidebar con controles
with st.sidebar:
    st.header("Controles")
    show_raw_data = st.checkbox("Mostrar datos crudos")
    selected_year = st.selectbox("A√±o del dataset", [2019])
    selected_continent = st.multiselect("Filtrar por continente", df['Continent'].unique())

# Filtrado de datos
if selected_continent:
    df = df[df['Continent'].isin(selected_continent)]

# Secci√≥n de datos
if show_raw_data:
    st.subheader("Datos Crudos")
    st.dataframe(df, use_container_width=True)

# Estad√≠sticas b√°sicas
st.subheader("Estad√≠sticas B√°sicas")
cols = st.columns(3)
with cols[0]:
    st.metric("Pa√≠ses analizados", df['Country or region'].nunique())
with cols[1]:
    st.metric("Puntuaci√≥n promedio", f"{df['Score'].mean():.2f}")
with cols[2]:
    st.metric("A√±o del estudio", selected_year)

# An√°lisis de distribuci√≥n
st.subheader("Distribuci√≥n del √çndice de Felicidad")
fig, ax = plt.subplots(figsize=(10, 6))
sns.histplot(df['Score'], kde=True, binwidth=0.8, ax=ax)
plt.title('Distribuci√≥n de Happiness Score')
plt.xlabel('Puntuaci√≥n')
plt.ylabel('Frecuencia')
st.pyplot(fig)

with st.expander("Conclusiones - Distribuci√≥n"):
    st.markdown("""
    - La distribuci√≥n del √≠ndice de felicidad sigue una curva aproximadamente normal
    - La mayor√≠a de pa√≠ses se concentran entre 4.5 y 6.5 puntos
    - Existen valores extremos en ambos extremos de la escala
    - Los pa√≠ses n√≥rdicos lideran consistentemente los primeros puestos
    """)

# Correlaciones
st.subheader("Relaci√≥n entre Variables")
col1, col2 = st.columns(2)

with col1:
    x_axis = st.selectbox("Variable X", df.select_dtypes(include=np.number).columns.tolist(), index=3)
with col2:
    y_axis = st.selectbox("Variable Y", df.select_dtypes(include=np.number).columns.tolist(), index=2)

fig = px.scatter(df, x=x_axis, y=y_axis, color='Continent', hover_name='Country or region',
                 title=f"{x_axis} vs {y_axis}")
st.plotly_chart(fig, use_container_width=True)

with st.expander("Conclusiones - Correlaciones"):
    st.markdown("""
    - El PIB per c√°pita muestra la correlaci√≥n m√°s fuerte con la felicidad
    - El soporte social es el segundo factor m√°s influyente
    - La esperanza de vida saludable tiene una relaci√≥n positiva significativa
    - La percepci√≥n de corrupci√≥n muestra una correlaci√≥n negativa d√©bil
    """)

# An√°lisis por continente
st.subheader("Comparativa por Continente")
continent_analysis = df.groupby('Continent').agg({
    'Score': 'mean',
    'GDP per capita': 'mean',
    'Social support': 'mean'
}).reset_index()

fig = px.bar(continent_analysis, x='Continent', y='Score', 
             title='Puntuaci√≥n Promedio por Continente',
             color='Continent')
st.plotly_chart(fig, use_container_width=True)

# Secci√≥n de Distribuci√≥n de Pa√≠ses por Continente
st.subheader("Distribuci√≥n de Pa√≠ses por Continente")

# C√°lculo de la distribuci√≥n
continents_groups = df.groupby('Continent')['Continent'].agg('count')

# Crear dos columnas para el gr√°fico y la tabla
col1, col2 = st.columns([2, 1])

with col1:
    # Gr√°fico de barras
    fig, ax = plt.subplots(figsize=(10, 6))
    plt.bar(continents_groups.index, continents_groups.values, color='skyblue')
    plt.title('N√∫mero de Pa√≠ses por Continente')
    plt.xlabel('Continente')
    plt.ylabel('Cantidad de Pa√≠ses')
    plt.xticks(rotation=45)
    st.pyplot(fig)

# Secci√≥n de Desviaci√≥n Local
st.subheader("Desviaci√≥n Local de Felicidad por Pa√≠s")

# Explicaci√≥n de la m√©trica
st.markdown("""
En nuestra regi√≥n, el √≠ndice de felicidad de algunos pa√≠ses puede tener una variaci√≥n significativa con respecto al √≠ndice de felicidad de su continente. 
Algunos pa√≠ses muestran una variaci√≥n positiva y otros una situaci√≥n m√°s desfavorable. Con este nuevo c√°lculo pretendemos reflejar esa **Desviaci√≥n Local**.
""")

st.latex(r"""
DL_i = Score_i - \frac{1}{n_c} \sum_{j \in C_i} Score_j
""")

# Explicaci√≥n de la f√≥rmula
st.markdown("""
Donde:
- $DL_i$ es la Desviaci√≥n Local del pa√≠s $i$
- $Score_i$ es el Score de felicidad del pa√≠s $i$ 
- $C_i$ es el conjunto de pa√≠ses del continente al que pertenece el pa√≠s $i$
- $n_c$ es el n√∫mero de pa√≠ses en el continente $C_i$
- $\sum_{j \in C_i} Score_j$ es la suma de los Scores de todos los pa√≠ses del continente $C_i$
""")

# C√°lculo de la Desviaci√≥n Local
media_por_continente = df.groupby('Continent')['Score'].transform('mean')
df['Local Deviation'] = df['Score'] - media_por_continente

# Mostrar los primeros 10 resultados
st.markdown("**Primeros 10 resultados:**")
st.dataframe(df[['Country or region', 'Continent', 'Score', 'Local Deviation']].head(10), use_container_width=True)

# Gr√°fico de desviaciones por continente
st.markdown("**Distribuci√≥n de Desviaciones por Continente**")
fig = px.box(df, x='Continent', y='Local Deviation', color='Continent',
             points="all", hover_data=['Country or region'],
             title="Distribuci√≥n de Desviaciones Locales por Continente")
st.plotly_chart(fig, use_container_width=True)

# Tabla con los pa√≠ses con mayor y menor desviaci√≥n
st.markdown("**Pa√≠ses con Mayor y Menor Desviaci√≥n Local**")
col1, col2 = st.columns(2)

with col1:
    st.markdown("**Mayor Desviaci√≥n Positiva**")
    top_positive = df.nlargest(5, 'Local Deviation')[['Country or region', 'Continent', 'Local Deviation']]
    st.dataframe(top_positive.style.format({'Local Deviation': '{:.2f}'}), use_container_width=True)

with col2:
    st.markdown("**Mayor Desviaci√≥n Negativa**")
    top_negative = df.nsmallest(5, 'Local Deviation')[['Country or region', 'Continent', 'Local Deviation']]
    st.dataframe(top_negative.style.format({'Local Deviation': '{:.2f}'}), use_container_width=True)

# Conclusiones en secci√≥n expandible
with st.expander("Conclusiones - Desviaci√≥n Local"):
    st.markdown("""
    - Los pa√≠ses n√≥rdicos muestran consistentemente las mayores desviaciones positivas
    - Algunos pa√≠ses africanos presentan las mayores desviaciones negativas
    - Am√©rica muestra una alta variabilidad en sus desviaciones
    - Ocean√≠a tiene una distribuci√≥n m√°s compacta, con menos variabilidad
    - La desviaci√≥n local ayuda a identificar casos at√≠picos y patrones regionales
    """)

# Conclusiones en secci√≥n expandible
with st.expander("Conclusiones - Distribuci√≥n por Continente"):
    st.markdown("""
    - **Europa** tiene la mayor representaci√≥n en el estudio
    - **√Åfrica** muestra una alta participaci√≥n, reflejando su diversidad
    - **Ocean√≠a** tiene la menor cantidad de pa√≠ses incluidos
    - La distribuci√≥n refleja el enfoque global del estudio
    - Am√©rica est√° dividida en Norte y Sur para un an√°lisis m√°s detallado
    """)

with st.expander("Conclusiones - Comparativa Continental"):
    st.markdown("""
    - Europa lidera en todos los indicadores principales
    - Ocean√≠a muestra valores altos a pesar de su menor densidad poblacional
    - √Åfrica presenta los valores m√°s bajos en todas las m√©tricas
    - Am√©rica del Norte tiene mayor variabilidad en los resultados
    """)

#Pruebas de hip√≥tesis
st.header("Pruebas de Hip√≥tesis")
st.subheader("Prueba de hipotesis unilateral sobre la media de felicidad")

st.markdown("""
En esta secci√≥n, se realizar√° una prueba de hip√≥tesis unilateral para determinar si el valor esperado del Score es mayor que 5.13.Resultado alcanzado por el mismo estudio que agrupo estos datos en el a√±o 2018.
""")

scores = df['Score']
    
    # Par√°metros de la prueba
mu_0 = 5.13
alpha = 0.05
    
# C√°lculos estad√≠sticos
sample_mean = scores.mean()
sample_std = scores.std()
n = len(scores)
t_statistic = (sample_mean - mu_0) / (sample_std / np.sqrt(n))
dof = n - 1  # Cambiado de 'df' para evitar conflicto con el DataFrame
p_value = 1 - stats.t.cdf(t_statistic, dof)
t_critico = stats.t.ppf(1 - alpha, dof)
    
# Crear visualizaci√≥n
fig, ax = plt.subplots(figsize=(10, 6))
x = np.linspace(stats.t.ppf(0.001, dof), stats.t.ppf(0.999, dof), 100)
y = stats.t.pdf(x, dof)
    
ax.plot(x, y, label='Distribuci√≥n t')
ax.fill_between(x, y, where=(x >= t_critico), color='red', alpha=0.3, label='Regi√≥n de rechazo')
ax.axvline(t_statistic, color='green', linestyle='--', label='Estad√≠stico t observado')
ax.axvline(t_critico, color='black', linestyle=':', label='Valor cr√≠tico')
    
ax.set_title('Prueba de Hip√≥tesis Unilateral para el Valor Esperado del Score')
ax.set_xlabel('Estad√≠stico t')
ax.set_ylabel('Densidad de Probabilidad')
ax.legend()
ax.grid(True)
    
st.pyplot(fig)
    
# Mostrar conclusiones
st.subheader("Resultados de la Prueba de Hip√≥tesis")
st.markdown(f"""
    - **Hip√≥tesis nula (H‚ÇÄ):** Œº ‚â§ {mu_0}
    - **Hip√≥tesis alternativa (H‚ÇÅ):** Œº > {mu_0}
    - **Estad√≠stico t calculado:** {t_statistic:.4f}
    - **Valor cr√≠tico:** {t_critico:.4f}
    - **P-valor obtenido:** {p_value:.4f}
    - **Media muestral:** {sample_mean:.4f}
    - **Desviaci√≥n est√°ndar muestral:** {sample_std:.4f}
    """)
    
    # Conclusi√≥n final
if p_value < alpha:
        st.success("**Conclusi√≥n:** Rechazar H‚ÇÄ")
        st.info(f"Hay evidencia estad√≠stica significativa (Œ± = {alpha}) para afirmar que el valor esperado del Score es mayor que {mu_0}")
else:
        st.error("**Conclusi√≥n:** No rechazar H‚ÇÄ")
        st.warning(f"No hay evidencia estad√≠stica suficiente (Œ± = {alpha}) para afirmar que el valor esperado del Score sea mayor que {mu_0}")

st.subheader("Prueba de hipotesis para dos poblaciones")
st.markdown("""Dado que anteriormente se analizaron los datos de un pa√≠s respecto a su continente , un an√°lisis interesante podr√≠a ser establecer comparaciones entre los continentes , dado que cada uno en si tiene sus caracter√≠sticas en cada uno de los aspectos medidos en el conjunto de datos .Veamos que influencia tiene esto sobre su *felicidad*.
""")
# Prueba de hip√≥tesis para dos poblaciones

# Secci√≥n de Comparativa √Åfrica vs Europa
st.markdown("""### Distribuci√≥n de la Felicidad en √Åfrica y Europa ü§îüìä

El siguiente histograma muestra la distribuci√≥n comparativa de los scores de felicidad entre los pa√≠ses africanos y europeos. Las barras superpuestas permiten visualizar las diferencias en los niveles de felicidad entre ambos continentes y evaluar la hip√≥tesis de que los pa√≠ses africanos tienden a tener un score de felicidad menor a 5.5 y por ende menor que el alto √≠ndice existente en los pa√≠ses europeos.
""")
# Filtrar datos
africa_scores = df[df['Continent'] == 'Africa']['Score']
europe_scores = df[df['Continent'] == 'Europe']['Score']

# Crear dos columnas para organizar el contenido
col1, col2 = st.columns([2, 1])

with col1:
    # Histogramas superpuestos
    st.markdown("**Distribuci√≥n de Puntuaciones de Felicidad**")
    fig1, ax1 = plt.subplots(figsize=(10, 6))
    ax1.hist(africa_scores, bins=15, alpha=0.5, label='√Åfrica', color='orange')
    ax1.hist(europe_scores, bins=15, alpha=0.5, label='Europa', color='blue')
    ax1.set_xlabel('Puntuaci√≥n de Felicidad')
    ax1.set_ylabel('Frecuencia')
    ax1.set_title('Distribuci√≥n de Puntuaciones: √Åfrica vs Europa')
    ax1.legend()
    st.pyplot(fig1)

with col2:
    # Mostrar promedios
    st.markdown("**Promedios de Felicidad**")
    st.metric("√Åfrica", f"{africa_scores.mean():.2f}")
    st.metric("Europa", f"{europe_scores.mean():.2f}")

# Pruebas estad√≠sticas
st.subheader("An√°lisis Estad√≠stico")

# --- Prueba t de Student ---
st.subheader("Prueba t de Student para muestras independientes"  )
st.markdown("""
Esta prueba compara si existen diferencias significativas entre las medias de los scores de Europa y √Åfrica.
Se plantean las hip√≥tesis:  
- H‚ÇÄ: Œº_Europa = Œº_√Åfrica (No hay diferencia en las medias)
- H‚ÇÅ: Œº_Europa ‚â† Œº_√Åfrica (Existe diferencia significativa)
""")

t_stat, p_value = ttest_ind(europe_scores, africa_scores)
st.markdown("**Resultados:**")
st.write(f"- Estad√≠stico t: {t_stat:.4f} (Magnitud de la diferencia estandarizada)")
st.write(f"- Valor p: {p_value:.4e} (Probabilidad de observar tal diferencia si H‚ÇÄ es cierta)")

# Interpretaci√≥n
st.markdown("""
**Interpretaci√≥n:**  
Un valor p menor que 0.05 sugiere evidencia suficiente para rechazar la hip√≥tesis nula, 
indicando que la diferencia observada en los promedios no es atribuible al azar. 
La direcci√≥n de la diferencia se determina comparando las medias reales de los grupos.
""")

# --- Prueba de Levene ---
st.subheader("Prueba de Levene para Homogeneidad de Varianzas")
st.markdown("""
Eval√∫a si ambos grupos mantienen varianzas iguales, requisito fundamental para 
la validez de la prueba t est√°ndar. Las hip√≥tesis son:  
- H‚ÇÄ: œÉ¬≤_Europa = œÉ¬≤_√Åfrica (Homogeneidad de varianzas)
- H‚ÇÅ: œÉ¬≤_Europa ‚â† œÉ¬≤_√Åfrica (Heterogeneidad de varianzas)
""")

levene_stat, levene_pvalue = levene(europe_scores, africa_scores)
st.markdown("**Resultados:**")
st.write(f"- Estad√≠stico: {levene_stat:.4f} (Medida de discrepancia entre varianzas)")
st.write(f"- Valor p: {levene_pvalue:.4f} (Probabilidad de observar tal discrepancia si H‚ÇÄ es cierta)")

# Interpretaci√≥n
st.markdown("""
**Interpretaci√≥n:**  
Un valor p < 0.05 indicar√≠a violaci√≥n del supuesto de homogeneidad, requiriendo 
el uso de ajustes como la correcci√≥n de Welch en la prueba t. Valores altos sugieren 
que las varianzas son estad√≠sticamente comparables, validando el uso de la prueba t cl√°sica.
""")

# Conclusi√≥n final
with st.expander("Conclusiones - Comparativa √Åfrica vs Europa"):
    st.markdown("""
    ### Hallazgos Principales:
    1. **Diferencias Significativas:**
       - Existe una diferencia estad√≠sticamente significativa entre los √≠ndices de felicidad de √Åfrica y Europa (p < 0.001)
       - Europa muestra puntuaciones consistentemente m√°s altas

    2. **Distribuci√≥n de Datos:**
       - Las puntuaciones europeas est√°n m√°s concentradas en el rango superior
       - √Åfrica presenta una distribuci√≥n m√°s amplia y sesgada hacia valores m√°s bajos

    3. **Normalidad de Datos:**
       - Ambos continentes muestran desviaciones de la normalidad en los extremos de la distribuci√≥n
       - Europa presenta una distribuci√≥n m√°s cercana a la normalidad

    4. **Homogeneidad de Varianzas:**
       - Las varianzas no son homog√©neas (p < 0.05), lo que sugiere mayor variabilidad en √Åfrica

    ### Implicaciones:
    - Las diferencias culturales, econ√≥micas y sociales entre continentes tienen un impacto significativo en los niveles de felicidad
    - Los pa√≠ses africanos podr√≠an beneficiarse de pol√≠ticas p√∫blicas enfocadas en mejorar los factores que m√°s impactan la felicidad
    - Europa podr√≠a servir como modelo para identificar pr√°cticas exitosas en la promoci√≥n del bienestar social
    """)

# Secci√≥n de Cambios Realizados
st.subheader("Cambios Realizados: Test de Normalidad sobre el Score")

# Cargar los datos
df = pd.read_csv('2019.csv')  # Aseg√∫rate de que el archivo est√© en la misma carpeta
scores = df['Score']

# Prueba de Shapiro-Wilk
st.markdown("## Test de Shapiro-Wilk üìàüîç")

# Justificaci√≥n del uso de Shapiro-Wilk
st.markdown("### Justificaci√≥n del Uso de Shapiro-Wilk")
st.markdown("""
El test de Shapiro-Wilk es la mejor opci√≥n para esta base de datos porque es especialmente adecuado para muestras de tama√±o peque√±o a moderado, como es el caso de los 156 pa√≠ses incluidos en el ranking de felicidad. Este test tiene una alta potencia estad√≠stica para detectar desviaciones de la normalidad en muestras de este tama√±o, lo que lo hace m√°s confiable que otros tests como el de Kolmogorov-Smirnov, que es menos sensible, o el de Anderson-Darling, que es m√°s √∫til para muestras m√°s grandes o cuando se quiere enfocar en las colas de la distribuci√≥n. Adem√°s, el test de Shapiro-Wilk es ampliamente utilizado y reconocido en la pr√°ctica estad√≠stica, lo que lo convierte en una opci√≥n robusta y adecuada para evaluar la normalidad de los datos en este contexto.
""")
shapiro_test = stats.shapiro(scores)
st.write(f"- **Estad√≠stico:** {shapiro_test.statistic:.4f}")
st.write(f"- **Valor p:** {shapiro_test.pvalue:.4f}")

# Interpretaci√≥n del Test de Shapiro-Wilk
alpha = 0.05  # Nivel de significancia
st.markdown("""### Resultados del Test de Shapiro-Wilk e interpretaci√≥n final
    . Estad√≠stico W cercano a 1 ‚úÖ  
    . P-valor > 0.05 ‚úÖ  
    . Interpretaci√≥n: No hay evidencia para rechazar normalidad  
""")
if shapiro_test.pvalue > alpha:
    st.success("**Conclusi√≥n:** Los datos parecen seguir una distribuci√≥n normal seg√∫n Shapiro-Wilk.")
else:
    st.error("**Conclusi√≥n:** Los datos NO parecen seguir una distribuci√≥n normal seg√∫n Shapiro-Wilk.")

# Visualizaciones para evaluar normalidad
st.markdown("### Visualizaciones para Evaluar Normalidad")

# Crear una figura con tres subplots
fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(15, 5))

# 1. Q-Q Plot (Gr√°fico Cuantil-Cuantil) usando scipy.stats.probplot
stats.probplot(scores, plot=ax1)
ax1.set_title('Q-Q Plot')

# 2. Histograma con curva normal
sns.histplot(scores, kde=True, ax=ax2)
ax2.set_title('Histograma con Distribuci√≥n Normal')

# 3. Boxplot
sns.boxplot(x=scores, ax=ax3)
ax3.set_title('Boxplot')

plt.tight_layout()
st.pyplot(fig)

# Regresion lineal SCORE y GDP per capita
st.subheader("Regresi√≥n Lineal")
st.markdown("""Evidentemente, nuestros datos est√°n relacionados con numerosos √≠ndices de los campos economicos, sociales y de la salud. Ser√≠a interesante visualizar que tan realacionados est√° alguno de estos datos con el √≠ndice de la Felicidad (score). Para ello utilizaremos Regresi√≥n Lineal, la cual es una t√©cnica que establece una l√≠nea recta en el comportamiento de nuestros datos para identificar que tan relacionados est√°n.

### Elecci√≥n de Variable Independiente
Antes de realizar el an√°lisis de la regresi√≥n, debemos seleccionar cual ser√° nuestra variable independiente. En este caso, elegiremos el GBP per Capita. Ya que como se muestra en la matriz de correlaci√≥n es la variable m√°s relacionada con el Score entre todas las dem√°s. 
            """)

df_numericas = df.select_dtypes(include=['float64', 'int64'])
correlation_matrix = df_numericas.corr()
plt.figure(figsize=(12, 8))
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm')
plt.title('Matriz de correlaci√≥n')
st.pyplot(plt)

st.markdown(""" #### Ya seleccionada la variable independiente (GDP per capita), procederemos a realizar el an√°lisis de la regresi√≥n lineal. """)

# An√°lisis de la regresion lineal 

# Preparaci√≥n de variables
x = df[['GDP per capita']]
y = df['Score']

# Modelo de regresi√≥n con scikit-learn
model = LinearRegression()
model.fit(x, y)
intercept = model.intercept_
slope = model.coef_[0]

# Mostrar resultados de la regresi√≥n
st.subheader("An√°lisis de la Regresi√≥n Lineal")
st.write(f"Intersecci√≥n: **{intercept:.4f}**")
st.write(f"Pendiente: **{slope:.4f}**")
st.write(f"Ecuaci√≥n de la recta: **y = {intercept:.4f} + {slope:.4f}x**")

# Gr√°fico de regresi√≥n
fig, ax = plt.subplots()
ax.scatter(x, y, color='blue', alpha=0.5, label='Datos reales')
ax.plot(x, model.predict(x), color='red', linewidth=2, label='L√≠nea de regresi√≥n')
ax.set_xlabel('PIB per c√°pita')
ax.set_ylabel('Score')
ax.set_title('Relaci√≥n entre Score y PIB per c√°pita')
ax.grid(True)
ax.legend()
st.pyplot(fig)

# Modelo statsmodels para an√°lisis detallado
x_sm = sm.add_constant(x)
model_sm = sm.OLS(y, x_sm).fit()

# Resumen del modelo
st.subheader("An√°lisis Estad√≠stico Detallado")
st.text(model_sm.summary().as_text())
residuals = model_sm.resid
y_pred = model.predict(x)

st.markdown(""" ### M√©tricas principales
1. Notemos el valor del R-Squared que es de 0.630, esto quiere decir que el GBP percapita influye en un 63% de la variaci√≥n del Score de Felicidad analizado en este trabajo.
   
2. El valor de Prob(F-static) es extredamente peque√±o, lo cual nos da a entender que este modelo es estad√≠sticamente significativo y confiable.
   
3. Coeficientes: El valor del score cuando GBP per capita es 0, es de 3.3993 (valor const en el summary), que es a su vez el intercepto calculado anteriormente. La pendiente es de 2.2181, esto que nos quiere decir: que una unidad de GBP per Capita aumenta el Score en 2.2181 su valor.
   
4. El valor p asociado a los test t (usado para ver si un coeficiente es significativamente distinto de 0) es de 0.000, lo cual nos da a entender que el coeficiente de GBP per Capita es estad√≠sticamente significativo y confiable.

### Otras m√©tricas de interes
1. Durbin-Watson: 1.378 (utilizado para detectar autocorrelaci√≥n en los residuos).

2. Omnibus y Prob(Omnibus): Tests de normalidad para los residuos (valores p > 0.05 sugieren que los residuos se distribuyen normalmente).

3. Jarque-Bera (JB) y Prob(JB): Tambi√©n pruebas de normalidad.

4. Kurtosis: 2.742 (medida de la ‚Äúacuminaci√≥n‚Äù de la distribuci√≥n de los residuos).

5. Cond. No.: 4.77 (n√∫mero de condici√≥n, que indica si hay problemas de multicolinealidad).
""")

# Gr√°fico de residuos
st.header("An√°lisis de Residuos üîçüöÆ")
st.markdown("""Analizaremos cada uno de los supuestos del modelo para verificar si nuestro modelo, valga la redundancia, es correcto
1. Los errores ($e_1$, ... ,$e_n$) son independientes
2. El valor esperado del error esperado $e_i$ es cero 
3. Homocedasticidad
4. Los errores adem√°s son identicamente distribuidos y siguen una distribuci√≥n normal con media cero y varianza $\sigma^2$
   
Grafiquemos los residuos para saber si el modelo cumple los supuestos del modelo 
""")
fig_res, ax_res = plt.subplots()
ax_res.scatter(y_pred, residuals, color='green', alpha=0.5)
ax_res.axhline(y=0, color='red', linestyle='--')
ax_res.set_xlabel('Valores Predichos')
ax_res.set_ylabel('Residuos')
ax_res.set_title('Residuos vs. Valores Predichos')
st.pyplot(fig_res)

# Histograma de los residuos
sns.histplot(residuals, kde=True)
plt.xlabel('Residuos')
plt.title('Histograma de los residuos')
st.pyplot(plt)

# Conclusiones
st.subheader("Conclusiones Finales para la Regresi√≥n Lineal")
conclusion = """
**Interpretaci√≥n de los resultados y validaci√≥n de supuestos:**

1. **Significancia estad√≠stica:** 
   - El valor p para el PIB per c√°pita , indica que el efecto es significante.
   
2. **Bondad de ajuste:**
   - El R-cuadrado ajustado (0.63) muestra que el modelo explica 63% de la variabilidad en el Score.

3. **Homocedasticidad:**
   - Se cumple homocedasticidad , o sea la varianza de los errores es constante .

4. **Normalidad de residuos:**
   - Distribuci√≥n Normal‚úÖ (Valor p Jarque-Bera: 1.244).

5. **Autocorrelaci√≥n:**
    - DW ‚âà 2: No hay autocorrelaci√≥n (residuos independientes).

    - DW < 1.5: Sugiere autocorrelaci√≥n positiva (los residuos est√°n correlacionados en el tiempo).

    - DW > 2.5: Sugiere autocorrelaci√≥n negativa.
   
    **En este caso** se aprecia con un valor de :(Durbin-Watson: 1.378) , una **leve correlaci√≥n positiva** pero no es cr√≠tico.
"""

st.markdown(conclusion)

st.subheader("Regresi√≥n lineal m√∫ltiple ü™¢")

st.markdown("""La regresi√≥n lineal m√∫ltiple es una extensi√≥n de la regresi√≥n lineal simple, que permite analizar la relaci√≥n entre una variable dependiente y dos o m√°s variables independientes. Mientras que la regresi√≥n lineal simple considera solo una variable independiente, la regresi√≥n lineal m√∫ltiple proporciona una forma m√°s completa de entender y predecir los valores de la variable dependiente al considerar m√∫ltiples factores simult√°neamente.

Procederemos de manera similar, es decir: primero seleccionaremos las mejores variables dependientes y luego procederemos con el an√°lisis de regresi√≥n lineal m√∫ltiple.

### Elecci√≥n de las mejores Variables ‚öôÔ∏è
Para elegir las mejores variables independientes, debemos tener en cuenta que estas deben estar relacionadas con el Score y a su vez no deben estar muy relacionadas entre ellas. Para esto utilizaremos un m√©todo de elecci√≥n de caracater√≠sticas el cual recursivamente determina que dos datos son los adecuados para un analisis de regresi√≥n lineal m√∫ltiple. Comprobaremos si en efecto esos datos son correctos con un an√°lisis de inflaci√≥n de la varianza. Finalmente realizaremos el an√°lisis de la regresi√≥n e interpretaremos los resultados.
""")

X = df_numericas.drop(columns=['Score'])
y = df['Score']

# Modelo de regresi√≥n lineal
model = LinearRegression()

# Eliminaci√≥n recursiva de caracter√≠sticas
rfe = RFE(estimator=model, n_features_to_select=3)
fit = rfe.fit(X, y)

# Resultados
selected_features = X.columns[fit.support_]
st.write("### Variables seleccionadas:")
st.write(selected_features)

st.markdown(""" ### Las variables seleccionadas son aquellas que:

- Maximizan la capacidad predictiva del modelo.

- Minimizan la redundancia (es decir, no est√°n altamente correlacionadas entre s√≠).

- Contribuyen significativamente a explicar la variabilidad de y.
            
    ### An√°lisis de la multicolinealidad üìä
            Hagamos un an√°lisis del factor inlfaci√≥n de la varianza para determinar si a√∫n debemos suprimir alguno de estos datos.
""")
X_selected = sm.add_constant(X[selected_features])

# Calcular VIF para cada variable seleccionada
vif = pd.DataFrame()
vif["Variable"] = X_selected.columns
vif["VIF"] = [variance_inflation_factor(X_selected.values, i) for i in range(X_selected.shape[1])]

st.write(vif)
st.markdown(""" ### 
                       ‚úÖ Los VIF de las variables independientes son todos bastante bajos, todos menores que 5 lo que sugiere que no hay un problema significativo 
            de multicolinealidad entre ellas. Por tanto podemos proceder con un analisis de regresi√≥n lineal m√∫ltiple utilizando estos tres datos
            """)

st.subheader("Regresi√≥n lineal m√∫ltiple")
# Regresi√≥n m√∫ltiple 
df = pd.read_csv('2019.csv')

# Preparar las variables independientes seleccionadas
X = df[['Social support', 'Healthy life expectancy', 'Freedom to make life choices']]
y = df['Score']

# Agregar una constante
X = sm.add_constant(X)

# Ajustar el modelo de regresi√≥n lineal m√∫ltiple
model_multiple = sm.OLS(y, X).fit()

# Resumen del modelo
summary = model_multiple.summary()
st.write(summary)

st.subheader("An√°lisis de los resultados de la Regresi√≥n Lineal M√∫ltiple")

st.write("""
### 1. Informaci√≥n General del Modelo
- **Dep. Variable: Score**: Variable dependiente que se busca predecir.
- **R-squared: 0.750**: El 75% de la variabilidad del "Score" es explicado por las variables independientes (Social support, Healthy life expectancy, y Freedom to make life choices). Indica un buen ajuste del modelo.
- **Adj. R-squared: 0.745**: Ajusta el \( R^2 \) por el n√∫mero de predictores. El valor cercano al \( R^2 \) original sugiere que las variables son relevantes.
- **F-statistic: 151.7 (Prob: 1.67e-45)**: El p-valor ‚âà 0 indica que al menos una variable independiente tiene un efecto significativo sobre el "Score". El modelo es estad√≠sticamente v√°lido.

### 2. M√©todo y Datos
- **Method: Least Squares**: M√©todo de estimaci√≥n utilizado (M√≠nimos Cuadrados Ordinarios, OLS).
- **No. Observations: 156**: N√∫mero de observaciones en el modelo.
- **Df Residuals: 152**: Grados de libertad de los residuos (156 observaciones - 3 variables - 1 intercepto).
- **Df Model: 3**: N√∫mero de variables independientes.

### 3. Coeficientes de la Regresi√≥n
- **const (Intercepto): 1.6233**: Valor predicho del "Score" cuando todas las variables independientes son cero.
- **Social support: 1.3613**: Por cada unidad que aumenta "Social support", el "Score" aumenta **1.3613 unidades** (p-valor = 0.000, muy significativo).
- **Healthy life expectancy: 1.9496**: Por cada unidad que aumenta "Healthy life expectancy", el "Score" aumenta **1.9496 unidades** (p-valor ‚âà 0, muy significativo).
- **Freedom to make life choices: 1.8450**: Por cada unidad que aumenta "Freedom to make life choices", el "Score" aumenta **1.8450 unidades** (p-valor ‚âà 0, muy significativo).
- **Intervalos de Confianza [0.025, 0.975]**: Rango donde se espera que est√© el verdadero coeficiente con un 95% de confianza. Ejemplo: Para "Social support", el coeficiente est√° entre 0.917 y 1.806.

### 4. Diagn√≥stico de Residuales
- **Omnibus: 2.545 (Prob: 0.280)**: Eval√∫a la normalidad de los residuos. P-valor > 0.05 sugiere que los residuos siguen una distribuci√≥n normal.
- **Jarque-Bera (JB): 2.493 (Prob: 0.287)**: Otra prueba de normalidad. P-valor > 0.05 refuerza que los residuos son normales.
- **Skew: -0.306**: Medida de asimetr√≠a. Un valor cercano a 0 indica simetr√≠a. -0.306 sugiere una ligera asimetr√≠a hacia la izquierda.
- **Kurtosis: 2.902**: Medida de la "cola" de la distribuci√≥n. Un valor cercano a 3 indica que los residuos tienen una distribuci√≥n similar a la normal.

### 5. Autocorrelaci√≥n y Multicolinealidad
- **Durbin-Watson: 1.535**: Eval√∫a la autocorrelaci√≥n de los residuos. Un valor cercano a 2 indica no autocorrelaci√≥n. 1.535 sugiere **leve autocorrelaci√≥n positiva**, pero no es cr√≠tica.
- **Cond. No.: 14.5**: N√∫mero de condici√≥n para detectar multicolinealidad. Valores < 30 indican baja multicolinealidad. 14.5 sugiere que no hay problemas graves.

### Conclusi√≥n Final
- **Variables Significativas**: Las tres variables (**Social support**, **Healthy life expectancy**, y **Freedom to make life choices**) son altamente significativas y tienen un impacto positivo en el "Score".
- **Ajuste del Modelo**: El modelo explica el 75% de la variabilidad del "Score" (\( R^2 = 0.75 \)) y es v√°lido estad√≠sticamente (F-statistic ‚âà 0).
- **Supuestos Cumplidos**: Los residuos son normales y no hay multicolinealidad grave.
- **Posible Mejora**: La leve autocorrelaci√≥n (Durbin-Watson = 1.535) podr√≠a requerir atenci√≥n si los datos son temporales.

""")

### Regresi√≥n Log√≠stica para Clasificaci√≥n de Felicidad
st.subheader("Regresi√≥n log√≠stica para clasificaci√≥n de felicidad üîÆüîç")
# Nos permite analizar la importancia de cada dato para la felicidad

# Importar bibliotecas necesarias
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import classification_report, confusion_matrix
import seaborn as sns

# Crear variable binaria basada en la media del Score
mean_happiness = df['Score'].mean()
df['is_happy'] = (df['Score'] > mean_happiness).astype(int)

# Seleccionar caracter√≠sticas para el modelo
features = ['GDP per capita', 'Social support', 'Healthy life expectancy', 
           'Freedom to make life choices', 'Generosity', 'Perceptions of corruption']
X = df[features]
y = df['is_happy']

# Escalar las caracter√≠sticas
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# Dividir datos en conjunto de entrenamiento y prueba
X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)

# Crear y entrenar el modelo
model = LogisticRegression(random_state=42)
model.fit(X_train, y_train)

# Realizar predicciones
y_pred = model.predict(X_test)


# Visualizar matriz de confusi√≥n
plt.figure(figsize=(8, 6))
cm = confusion_matrix(y_test, y_pred)
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')
plt.title('Matriz de Confusi√≥n')
plt.ylabel('Valor Real')
plt.xlabel('Predicci√≥n')
st.pyplot(plt)

# Calcular m√©tricas
accuracy = (cm[0,0] + cm[1,1]) / cm.sum()
precision = cm[1,1] / (cm[1,1] + cm[0,1])
recall = cm[1,1] / (cm[1,1] + cm[1,0])
f1 = 2 * (precision * recall) / (precision + recall)

st.write(f"\n ### M√©tricas del modelo:")
st.write(f"Exactitud (Accuracy): {accuracy:.2%}")
st.write(f"Precisi√≥n: {precision:.2%}")
st.write(f"Sensibilidad (Recall): {recall:.2%}")
st.write(f"F1-Score: {f1:.2%}")

# Interpretaci√≥n por cuadrante
st.write("\n ### Interpretaci√≥n de la matriz de confusi√≥n:")
st.write(f"Verdaderos Negativos (VN): {cm[0,0]} pa√≠ses correctamente clasificados como no felices")
st.write(f"Falsos Positivos (FP): {cm[0,1]} pa√≠ses incorrectamente clasificados como felices")
st.write(f"Falsos Negativos (FN): {cm[1,0]} pa√≠ses incorrectamente clasificados como no felices")
st.write(f"Verdaderos Positivos (VP): {cm[1,1]} pa√≠ses correctamente clasificados como felices")

# Analizar importancia de caracter√≠sticas
feature_importance = pd.DataFrame({
    'Feature': features,
    'Importance': abs(model.coef_[0])
})
feature_importance = feature_importance.sort_values('Importance', ascending=False)

plt.figure(figsize=(10, 6))
sns.barplot(x='Importance', y='Feature', data=feature_importance)
plt.title('Importancia de Caracter√≠sticas en la Predicci√≥n de Felicidad')
st.pyplot(plt)

# Ejemplo de predicci√≥n para un nuevo pa√≠s
def predict_happiness(country_data):
    # Escalar los datos
    scaled_data = scaler.transform([country_data])
    # Realizar predicci√≥n
    prediction = model.predict(scaled_data)
    probability = model.predict_proba(scaled_data)
    return prediction[0], probability[0]

# Ejemplo de uso
example_country = [1.0, 1.2, 0.8, 0.5, 0.2, 0.1]  # Valores ejemplo
prediction, probability = predict_happiness(example_country)
st.write("\nPredicci√≥n para pa√≠s hipot√©tico:")
st.write(f"Clasificaci√≥n: {'Feliz' if prediction == 1 else 'No feliz'}")
st.write(f"Probabilidad: {probability[1]:.2%} de ser feliz")

st.markdown("""## Factores m√°s Influyentes en la FelicidadüîÜ

El an√°lisis muestra que el **apoyo social** (social support) y la **esperanza de vida saludable** (healthy life expectancy) son los factores m√°s determinantes para la felicidad de un pa√≠s. Esto sugiere que las sociedades con fuertes redes de apoyo y buenos sistemas de salud tienden a ser m√°s felices.

Por otro lado, la **generosidad** y la **percepci√≥n de corrupci√≥n** mostraron una influencia considerablemente menor en el nivel de felicidad de los pa√≠ses, indicando que estos factores no son tan cruciales para determinar el bienestar general de una naci√≥n.

Esta informaci√≥n podr√≠a ser valiosa para orientar pol√≠ticas p√∫blicas hacia el fortalecimiento de sistemas de apoyo social y servicios de salud.""")

# Top 10 pa√≠ses
st.subheader("Top 10 Pa√≠ses m√°s Felices")
top_countries = df.nlargest(10, 'Score')[['Country or region', 'Score', 'Continent']]
st.dataframe(top_countries.style.background_gradient(cmap='Blues'), use_container_width=True)

# An√°lisis estad√≠stico avanzado
st.subheader("An√°lisis Estad√≠stico Detallado")
st.write("""
### Hallazgos Clave:
1. **Factores Determinantes:**
   - El 75% de la varianza en el √≠ndice se explica por factores econ√≥micos y sociales
   - El PIB y soporte social explican el 60% de las diferencias entre pa√≠ses

2. **Distribuci√≥n Regional:**
   - Europa contiene el 80% de los pa√≠ses en el top 20
   - √Åfrica representa el 90% de los pa√≠ses en el cuartil inferior

3. **Corrupci√≥n Percepcibida:**
   - Los pa√≠ses n√≥rdicos combinan alta confianza institucional con altos √≠ndices
   - La correlaci√≥n corrupci√≥n-felicidad es d√©bil (r = -0.15)
""")
# Mapa interactivo
st.subheader("Distribuci√≥n Geogr√°fica de la Felicidad")
fig = px.choropleth(df, locations="Country or region",
                    locationmode='country names',
                    color="Score", 
                    hover_name="Country or region",
                    color_continuous_scale=px.colors.sequential.Plasma,
                    title="Mapa Mundial de Felicidad")
st.plotly_chart(fig, use_container_width=True)
# Footer
st.markdown("---")
st.markdown("**Universidad de La Habana** - Facultad de Ciencias de la Computaci√≥n")
st.markdown("Proyecto de An√°lisis Estad√≠stico - 2024")